{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#folder = \"C:/cppd/D/CodePerformanceProblemDetection/5_1_FeaturesTokenExtractor/data\"\n",
    "#folder = \"D:/Project/CodePerformanceProblemDetection/5_1_FeaturesTokenExtractor/data\"\n",
    "folder = \"D:/Project/New_Project/Dataset/New_Dataset in folders\"\n",
    "\n",
    "path_log = \"D:/Project/CodePerformanceProblemDetection/5_1_FeaturesTokenExtractor/log.txt\"\n",
    "\n",
    "featuresFileName = \"featuresPSI.tsv\"\n",
    "statisticNumbersFileName = \"statisticsPSI.txt\"\n",
    "\n",
    "snipFolder = \"\"\n",
    "\n",
    "tokens = []\n",
    "\n",
    "token_matrix = []\n",
    "\n",
    "files_list = []\n",
    "token_list = []\n",
    "value_list = []\n",
    "\n",
    "value_matrix = []\n",
    "value_files_list = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Counter(object):\n",
    "    def __init__(self, lines, files, snippets):\n",
    "        self.lines = lines\n",
    "        self.files = files\n",
    "        self.snippets = snippets\n",
    "\n",
    "    def incLine(self):\n",
    "        self.lines = self.lines + 1\n",
    "\n",
    "    def incFile(self):\n",
    "        self.files = self.files + 1\n",
    "\n",
    "    def incSnippets(self):\n",
    "        self.snippets = self.snippets + 1\n",
    "\n",
    "    def getLines(self):\n",
    "        return self.lines\n",
    "\n",
    "    def getFiles(self):\n",
    "        return self.files\n",
    "\n",
    "    def getSnippets(self):\n",
    "        return self.snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_extractor_token():\n",
    "    counter = Counter(0, 0, 0)\n",
    "    for file in os.listdir(folder):\n",
    "        path = os.path.join(folder, file)\n",
    "        #path = folder + \"/\" + file\n",
    "        #path.replace(' ', '_')\n",
    "        if os.path.isfile(path) and path.endswith(\".txt\"):\n",
    "            counter.incFile()\n",
    "            extractTokenList(path, file, snipFolder, counter)\n",
    "        elif os.path.isdir(path):\n",
    "            createSnippetsDir(path, file, snipFolder, counter)\n",
    "    #print(token_matrix)\n",
    "    #print(tokens)\n",
    "    #print(len(tokens))\n",
    "    #print(counter.getFiles())\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createSnippetsDir(folder, repo, snipFolder, counter):\n",
    "    try:\n",
    "        for file in os.listdir(folder):\n",
    "            path = os.path.join(folder, file)\n",
    "            #path = folder + \"/\" + file\n",
    "            #path.replace(' ', '_')\n",
    "            if os.path.isfile(path) and path.endswith(\".txt\"):\n",
    "                counter.incFile()\n",
    "                extractTokenList(path, file, snipFolder, counter)\n",
    "            elif os.path.isdir(path):\n",
    "                createSnippetsDir(path, repo, snipFolder, counter)\n",
    "    except:\n",
    "        with open('bad_files.txt', 'w') as f:\n",
    "            f.write(folder + \"/\" + file)\n",
    "            f.write(\"\\n\")\n",
    "        pass\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import csv\n",
    "\n",
    "def extractTokenList(path, file, snipFolder, counter):\n",
    "    #f = open(path, 'r')\n",
    "    f = codecs.open(path, \"r\", \"utf_8_sig\" )\n",
    "    #fileOutput = open(path_log, 'w')\n",
    "    #fileOutput.write(path)\n",
    "    #fileOutput.write(\"\\n\")\n",
    "    #fileOutput.close()\n",
    "    token_types = []\n",
    "    value_types = []\n",
    "    for line in f:\n",
    "        token_types.append(line.split(' (')[0])\n",
    "        value_types.append(line.split(' (', 1)[1].rsplit(')', 1)[0])\n",
    "    #token_types = [line.split(' (')[0] for line in f]\n",
    "    #value_types = [(line.split(' (\\'', 1)[1]).rsplit('\\')', 1)[0] for line in f]\n",
    "    #token_types = [split_unicode_chrs(line)[0] for line in f]\n",
    "    #token_matrix.append(token_types)\n",
    "    files_list.append(path)\n",
    "    #value_matrix.append(value_types)\n",
    "    #value_files_list.append(path)\n",
    "    with open(path + \".token\", 'w') as tsv_file:\n",
    "        tsv_writer = csv.writer(tsv_file, delimiter=' ', lineterminator='\\n')\n",
    "        tsv_writer.writerow(token_types)\n",
    "    with open(path + \".value\", 'w') as tsv_file:\n",
    "        tsv_writer = csv.writer(tsv_file, delimiter=' ', lineterminator='\\n')\n",
    "        tsv_writer.writerow(value_types)\n",
    "    \n",
    "\n",
    "    #print(token_types)\n",
    "    #for t in token_types:\n",
    "    #    if t not in tokens:\n",
    "    #        tokens.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_extractor_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_list = list(map(lambda x: x + \".token\", files_list))\n",
    "value_list = list(map(lambda x: x + \".value\", files_list))\n",
    "\n",
    "import pickle\n",
    "\n",
    "class DataFilePath:\n",
    "    def __setitem__(self, index: int, value):\n",
    "        '''сохранить в файл index.data'''\n",
    "        with open('{}.data'.format(index), 'wb') as f:\n",
    "            pickle.dump(value, f)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        '''читать из файла index.data'''\n",
    "        with open('{}.data'.format(index), 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "file = DataFilePath()\n",
    "\n",
    "file[10] = token_list\n",
    "file[11] = value_list\n",
    "\n",
    "d1 = file[10]\n",
    "print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "16\n",
      "250\n",
      "284\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "#print(tokens)\n",
    "#print(token_matrix)\n",
    "#print(files_list)\n",
    "\n",
    "print(len(token_matrix))\n",
    "print(len(token_matrix[0]))\n",
    "print(len(token_matrix[10]))\n",
    "print(len(token_matrix[20]))\n",
    "print(len(files_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['package', 'WHITE_SPACE', 'IDENTIFIER', 'DOT', 'IDENTIFIER', 'DOT', 'IDENTIFIER', 'DOT', 'IDENTIFIER', 'DOT', 'IDENTIFIER', 'DOT', 'IDENTIFIER', 'WHITE_SPACE', 'IDENTIFIER', 'WHITE_SPACE', 'IDENTIFIER', 'DOT', 'IDENTIFIER', 'DOT', 'IDENTIFIER', 'DOT', 'IDENTIFIER', 'WHITE_SPACE', 'IDENTIFIER', 'WHITE_SPACE', 'IDENTIFIER', 'DOT', 'IDENTIFIER', 'DOT', 'IDENTIFIER', 'WHITE_SPACE', 'IDENTIFIER', 'WHITE_SPACE', 'IDENTIFIER', 'DOT', 'IDENTIFIER', 'DOT', 'IDENTIFIER', 'WHITE_SPACE', 'IDENTIFIER', 'WHITE_SPACE', 'IDENTIFIER', 'DOT', 'IDENTIFIER', 'WHITE_SPACE', 'IDENTIFIER', 'WHITE_SPACE', 'IDENTIFIER', 'DOT', 'IDENTIFIER', 'DOT', 'IDENTIFIER', 'WHITE_SPACE', 'IDENTIFIER', 'WHITE_SPACE', 'IDENTIFIER', 'DOT', 'IDENTIFIER', 'DOT', 'IDENTIFIER', 'WHITE_SPACE', 'KDoc', 'WHITE_SPACE', 'interface', 'WHITE_SPACE', 'IDENTIFIER', 'WHITE_SPACE', 'LBRACE', 'WHITE_SPACE', 'AT', 'IDENTIFIER', 'LPAR', 'OPEN_QUOTE', 'REGULAR_STRING_PART', 'CLOSING_QUOTE', 'RPAR', 'WHITE_SPACE', 'fun', 'WHITE_SPACE', 'IDENTIFIER', 'LPAR', 'RPAR', 'COLON', 'WHITE_SPACE', 'IDENTIFIER', 'LT', 'IDENTIFIER', 'LT', 'IDENTIFIER', 'LT', 'IDENTIFIER', 'GT', 'GT', 'GT', 'WHITE_SPACE', 'AT', 'IDENTIFIER', 'LPAR', 'OPEN_QUOTE', 'REGULAR_STRING_PART', 'CLOSING_QUOTE', 'RPAR', 'WHITE_SPACE', 'fun', 'WHITE_SPACE', 'IDENTIFIER', 'LPAR', 'RPAR', 'COLON', 'WHITE_SPACE', 'IDENTIFIER', 'LT', 'IDENTIFIER', 'LT', 'IDENTIFIER', 'GT', 'GT', 'WHITE_SPACE', 'AT', 'IDENTIFIER', 'LPAR', 'OPEN_QUOTE', 'REGULAR_STRING_PART', 'CLOSING_QUOTE', 'RPAR', 'WHITE_SPACE', 'fun', 'WHITE_SPACE', 'IDENTIFIER', 'LPAR', 'AT', 'IDENTIFIER', 'LPAR', 'OPEN_QUOTE', 'REGULAR_STRING_PART', 'CLOSING_QUOTE', 'RPAR', 'WHITE_SPACE', 'IDENTIFIER', 'COLON', 'WHITE_SPACE', 'IDENTIFIER', 'RPAR', 'COLON', 'WHITE_SPACE', 'IDENTIFIER', 'LT', 'IDENTIFIER', 'LT', 'IDENTIFIER', 'GT', 'GT', 'WHITE_SPACE', 'RBRACE']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "class DataFileTokens:\n",
    "    def __setitem__(self, index: int, value):\n",
    "        '''сохранить в файл index.data'''\n",
    "        with open('experiment/tokens/{}.data'.format(index), 'wb') as f:\n",
    "            pickle.dump(value, f)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        '''читать из файла index.data'''\n",
    "        with open('experiment/tokens/{}.data'.format(index), 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "file = DataFileTokens()\n",
    "\n",
    "for i in range(0, len(token_matrix)):\n",
    "    file[i] = token_matrix[i]\n",
    "\n",
    "d1 = file[11]\n",
    "print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Project/CodePerformanceProblemDetection/5_1_FeaturesTokenExtractor/data\\sources_2\\sources\\app\\src\\androidTest\\java\\com\\ground0\\transaction\\ExampleInstrumentedTest.txt\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "class DataFilePath:\n",
    "    def __setitem__(self, index: int, value):\n",
    "        '''сохранить в файл index.data'''\n",
    "        with open('experiment/files/{}.data'.format(index), 'wb') as f:\n",
    "            pickle.dump(value, f)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        '''читать из файла index.data'''\n",
    "        with open('experiment/files/{}.data'.format(index), 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "file = DataFilePath()\n",
    "\n",
    "file[0] = files_list\n",
    "\n",
    "d1 = file[0][1]\n",
    "print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 10 [-3]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "class DataFile:\n",
    "    def __setitem__(self, index: int, value):\n",
    "        '''сохранить в файл index.data'''\n",
    "        with open('{}.data'.format(index), 'wb') as f:\n",
    "            pickle.dump(value, f)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        '''читать из файла index.data'''\n",
    "        with open('{}.data'.format(index), 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "file = DataFile()\n",
    "# записать в файл file[индекс] - индекс.data\n",
    "file[0] = [[2, 1, 3, 4, 5], [11, 12, 13, 14, 15], [21, 22, 23, 24, 25]]\n",
    "file[1] = 10\n",
    "file[2] = {'123': [-1, -2, [-3]]}\n",
    "# читать из file[индекс] - индекс.data\n",
    "d1 = file[0][1][-1]  # 15\n",
    "d2 = file[1]  # 10\n",
    "d3 = file[2]['123'][2]  # [-3]\n",
    "print(d1, d2, d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "value_matrix = []\n",
    "value_files_list = []\n",
    "\n",
    "def feature_extractor_value():\n",
    "    counter = Counter(0, 0, 0)\n",
    "    for file in os.listdir(folder):\n",
    "        path = os.path.join(folder, file)\n",
    "        #path = folder + \"/\" + file\n",
    "        #path.replace(' ', '_')\n",
    "        if os.path.isfile(path) and path.endswith(\".txt\"):\n",
    "            counter.incFile()\n",
    "            extractTokenList(path, file, snipFolder, counter)\n",
    "        elif os.path.isdir(path):\n",
    "            createSnippetsDir(path, file, snipFolder, counter)\n",
    "    #print(token_matrix)\n",
    "    #print(tokens)\n",
    "    #print(len(tokens))\n",
    "    #print(counter.getFiles())\n",
    "    return\n",
    "\n",
    "def createSnippetsDir(folder, repo, snipFolder, counter):\n",
    "    try:\n",
    "        for file in os.listdir(folder):\n",
    "            path = os.path.join(folder, file)\n",
    "            #path = folder + \"/\" + file\n",
    "            #path.replace(' ', '_')\n",
    "            if os.path.isfile(path) and path.endswith(\".txt\"):\n",
    "                counter.incFile()\n",
    "                extractTokenList(path, file, snipFolder, counter)\n",
    "            elif os.path.isdir(path):\n",
    "                createSnippetsDir(path, repo, snipFolder, counter)\n",
    "    except:\n",
    "        print(folder + \"/\" + file)\n",
    "        print()\n",
    "        pass\n",
    "    return\n",
    "\n",
    "import codecs\n",
    "\n",
    "def extractTokenList(path, file, snipFolder, counter):\n",
    "    #f = open(path, 'r')\n",
    "    f = codecs.open(path, \"r\", \"utf_8_sig\" )\n",
    "    #fileOutput = open(path_log, 'w')\n",
    "    #fileOutput.write(path)\n",
    "    #fileOutput.write(\"\\n\")\n",
    "    #fileOutput.close()\n",
    "    value_types = [(line.split(' (\\'', 1)[1]).rsplit('\\')', 1)[0] for line in f]\n",
    "    #token_types = [split_unicode_chrs(line)[0] for line in f]\n",
    "    value_matrix.append(value_types)\n",
    "    value_files_list.append(path)\n",
    "    #print(token_types)\n",
    "    #for t in token_types:\n",
    "    #    if t not in tokens:\n",
    "    #        tokens.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_extractor_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['package', ' ', 'com', '.', 'ground0', '.', 'transaction', '.', 'core', '.', 'repository', '.', 'db', '.', 'util', '\\\\n\\\\n', 'import', ' ', 'android', '.', 'arch', '.', 'persistence', '.', 'room', '.', 'TypeConverter', '\\\\n', 'import', ' ', 'org', '.', 'threeten', '.', 'bp', '.', 'LocalDateTime', '\\\\n\\\\n', '/**\\\\n * Created by 00-00-00 on 05/05/18.\\\\n */', '\\\\n\\\\n', 'open', ' ', 'class', ' ', 'DateTypeConverter', ' ', '{', '\\\\n\\\\n  ', '@', 'TypeConverter', '\\\\n  ', 'fun', ' ', 'toDate', '(', 'value', ':', ' ', 'String', '?', ')', ':', ' ', 'LocalDateTime', ' ', '=', ' ', 'LocalDateTime', '.', 'parse', '(', 'value', ')', '\\\\n\\\\n  ', '@', 'TypeConverter', '\\\\n  ', 'fun', ' ', 'toString', '(', 'value', ':', ' ', 'LocalDateTime', '?', ')', ':', ' ', 'String', ' ', '=', ' ', 'value', '.', 'toString', '(', ')', '\\\\n\\\\n', '}']\n"
     ]
    }
   ],
   "source": [
    "print(value_matrix[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['package', ' ', 'com', '.', 'ground0', '.', 'transaction', '.', 'core', '.', 'repository', '.', 'network', '\\\\n\\\\n', 'import', ' ', 'com', '.', 'ground0', '.', 'model', '.', 'RetailTransaction', '\\\\n', 'import', ' ', 'io', '.', 'reactivex', '.', 'Flowable', '\\\\n', 'import', ' ', 'io', '.', 'reactivex', '.', 'Observable', '\\\\n', 'import', ' ', 'retrofit2', '.', 'Response', '\\\\n', 'import', ' ', 'retrofit2', '.', 'http', '.', 'GET', '\\\\n', 'import', ' ', 'retrofit2', '.', 'http', '.', 'Query', '\\\\n\\\\n', '/**\\\\n * Created by 00-00-00 on 05/05/18.\\\\n */', '\\\\n\\\\n', 'interface', ' ', 'ApiStore', ' ', '{', '\\\\n\\\\n  ', '@', 'GET', '(', '\"', 'transactions', '\"', ')', '\\\\n  ', 'fun', ' ', 'getTransactions', '(', ')', ':', ' ', 'Observable', '<', 'Response', '<', 'List', '<', 'RetailTransaction', '>', '>', '>', '\\\\n\\\\n  ', '@', 'GET', '(', '\"', 'non_existant', '\"', ')', '\\\\n  ', 'fun', ' ', 'getNon', '(', ')', ':', ' ', 'Observable', '<', 'Response', '<', 'Unit', '>', '>', '\\\\n\\\\n  ', '@', 'GET', '(', '\"', 'transaction/{transactionId}', '\"', ')', '\\\\n  ', 'fun', ' ', 'getTransaction', '(', '@', 'Query', '(', '\"', 'transactionId', '\"', ')', ' ', 'id', ':', ' ', 'Long', ')', ':', ' ', 'Observable', '<', 'Response', '<', 'RetailTransaction', '>', '>', '\\\\n\\\\n', '}']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "class DataFileValues:\n",
    "    def __setitem__(self, index: int, value):\n",
    "        '''сохранить в файл index.data'''\n",
    "        with open('experiment/values/{}.data'.format(index), 'wb') as f:\n",
    "            pickle.dump(value, f)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        '''читать из файла index.data'''\n",
    "        with open('experiment/values/{}.data'.format(index), 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "file = DataFileValues()\n",
    "\n",
    "for i in range(0, len(value_matrix)):\n",
    "    file[i] = value_matrix[i]\n",
    "\n",
    "d1 = file[11]\n",
    "print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
    "vectors = vectorizer.fit_transform(token_matrix)\n",
    "\n",
    "print(len(vectors.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 2 0 0 1 0 0 0 2 0 0 1 0 0 1 0 1 2 4 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "46\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "res = vectors.toarray()\n",
    "\n",
    "print(res[0])\n",
    "print(len(res[0]))\n",
    "print(len(res[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARROW', 'AT', 'BLOCK_COMMENT', 'CLOSING_QUOTE', 'COLON', 'COLONCOLON', 'COMMA', 'DOT', 'EOL_COMMENT', 'EQ', 'EQEQ', 'EXCL', 'GT', 'IDENTIFIER', 'INTEGER_LITERAL', 'KDoc', 'LBRACE', 'LBRACKET', 'LONG_TEMPLATE_ENTRY_END', 'LONG_TEMPLATE_ENTRY_START', 'LPAR', 'LT', 'MUL', 'OPEN_QUOTE', 'PLUS', 'QUEST', 'RBRACE', 'RBRACKET', 'REGULAR_STRING_PART', 'RPAR', 'WHITE_SPACE', 'class', 'else', 'false', 'fun', 'if', 'interface', 'null', 'object', 'package', 'return', 'super', 'this', 'true', 'val', 'var']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizerValue = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
    "vectorsValue = vectorizerValue.fit_transform(value_matrix)\n",
    "\n",
    "print(len(vectorsValue.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]\n",
      "470\n",
      "470\n"
     ]
    }
   ],
   "source": [
    "res = vectorsValue.toarray()\n",
    "\n",
    "print(res[0])\n",
    "print(len(res[0]))\n",
    "print(len(res[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42  2  0  0  5  5  0  0  6  0 39  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  9  0  2  1  0  2  8  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  3  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  2  2  3  2  2  2  0  0  0\n",
      "  0  0  0  0  6  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0\n",
      "  0  0  0  0  0  0  9  3  3  0  0  0  0  0  0  0  0  3  3  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  1  0  0  0  0  0  0  2  0  0  0  0  0  1  0  7  0  1  0  0  0  0  0  0\n",
      "  2  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0  0\n",
      "  0  0  0  0  0  2  0  0  2  0  0  0  0  0  0  0  0  0  0  0  6  1  6  0  0\n",
      "  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  2  0  0\n",
      "  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  2  0  1  0  0  1  0\n",
      "  0  0  0  0  0  0  0  0  1  0  0  0  0  1  0  1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  2  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
      "  0  1  1  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0  4  4]\n"
     ]
    }
   ],
   "source": [
    "print(res[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '${', '(', ')', '*', '+', ',', '->', '.', '/', '/**\\\\n   * Used for cases where T is Void, to make calls cleaner.\\\\n   */', \"/**\\\\n * A lifecycle-aware observable that sends only new updates after subscription, used for events like\\\\n * navigation and Snackbar messages.\\\\n *\\\\n *\\\\n * This avoids a common problem with events: on configuration change (like rotation) an update\\\\n * can be emitted if the observer is active. This LiveData only calls the observable if there's an\\\\n * explicit call to setValue() or call().\\\\n *\\\\n *\\\\n * Note that only one observer is going to be notified of changes.\\\\n */\", '/**\\\\n * Created by 00-00-00 on 04/05/18.\\\\n */', '/**\\\\n * Created by 00-00-00 on 05/05/18.\\\\n */', '/**\\\\n * Created by 00-00-00 on 06/05/18.\\\\n */', '/**\\\\n * Created by 00-00-00 on 07/05/18.\\\\n */', '/**\\\\n * Created by 00-00-00 on 08/05/18.\\\\n */', '/**\\\\n * Created by 00-00-00 on 10/05/18.\\\\n */', '/**\\\\n * Example local unit test, which will execute on the development machine (host).\\\\n *\\\\n * See [testing documentation](http://d.android.com/tools/testing).\\\\n */', '/**\\\\n * Instrumented test, which will execute on an Android device.\\\\n *\\\\n * See [testing documentation](http://d.android.com/tools/testing).\\\\n */', '/*\\\\n *  Copyright 2017 Google Inc.\\\\n *\\\\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\\\\n *  you may not use this file except in compliance with the License.\\\\n *  You may obtain a copy of the License at\\\\n *\\\\n *      http://www.apache.org/licenses/LICENSE-2.0\\\\n *\\\\n *  Unless required by applicable law or agreed to in writing, software\\\\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\\\\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\\\n *  See the License for the specific language governing permissions and\\\\n *  limitations under the License.\\\\n */', '// Context of the app under test.', '// Observe the internal MutableLiveData', '//To change body of created functions use File | Settings | File Templates.', '1', '2', '4', '404', ':', '::', '<', '=', '==', '>', '?', '@', 'API_VERSION', 'Adapter', 'AndroidJUnit4', 'AndroidSchedulers', 'AndroidThreeTen', 'ApiStore', 'AppCompatActivity', 'Application', 'Assert', 'AtomicBoolean', 'BaseActivity', 'BaseFragment', 'BindView', 'BuildConfig', 'Builder', 'Bundle', 'ButterKnife', 'Class', 'CloudStore', 'ColumnInfo', 'Context', 'Customer', 'DB write fail', 'DB write success', 'Dao', 'Database', 'Date', 'DateTimeFormatter', 'DateTypeConverter', 'Disposable', 'Entity', 'Error', 'ExampleInstrumentedTest', 'ExampleUnitTest', 'FORMATTER', 'FROM', 'Flowable', 'Fragment', 'Function', 'GET', 'GsonBuilder', 'GsonConverterFactory', 'HOST', 'HTTP error', 'Hello, Kotlin!', 'HttpStatusOperator', 'HttpStatusOperatorTest', 'ISO_OFFSET_DATE_TIME', 'Insert', 'InstrumentationRegistry', 'Int', 'Intent', 'ItemTransactionBinding', 'JsonDeserializationContext', 'JsonDeserializer', 'JsonElement', 'JsonPrimitive', 'JsonSerializationContext', 'JsonSerializer', 'LENGTH_SHORT', 'LayoutInflater', 'LifecycleOwner', 'LinearLayoutManager', 'List', 'LiveData', 'Loading transactions: ', 'LocalDateTime', 'LocalDateTimeConverter', 'LocalStore', 'Log', 'Long', 'Main2Activity', 'MainActivity', 'MainThread', 'MediaType', 'Multiple observers registered but only one will be notified of changes.', 'MutableLiveData', 'Observable', 'ObservableOperator', 'ObservableSource', 'Observer', 'Oh oh, dum dum ', 'On Error was called', 'On Error was calledq', 'On Success was called', 'OnClick', 'OnConflictStrategy', 'PrimaryKey', 'Query', 'R', 'REPLACE', 'RecyclerView', 'Repository', 'RepositoryImp', 'Response', 'ResponseBody', 'ResponseStatusOperator', 'RetailApplication', 'RetailTransaction', 'RetailTransactionDao', 'Retailer', 'Retrofit', 'Room', 'RoomDatabase', 'RunWith', 'Rx observable triggered ', 'RxJava2CallAdapterFactory', 'SELECT * FROM retail_transactions', 'SELECT * FROM retail_transactions WHERE id = :id LIMIT 1', 'Schedulers', 'SerializedName', 'SingleLiveEvent', 'SingleObserver', 'SingleSource', 'Snackbar', 'Something went wrong', 'String', 'Subscriber', 'System', 'T', 'TAG', 'TODO', 'Test', 'TextView', 'Throwable', 'Toast', 'TransactionListActivity', 'TransactionListAdapter', 'TransactionListItemViewModel', 'TransactionListItemViewModelFactory', 'TransactionListViewModel', 'Type', 'TypeConverter', 'TypeConverters', 'Unit', 'VERTICAL', 'View', 'ViewGroup', 'ViewHolder', 'ViewModel', 'ViewModelProviders', 'Yo, Shits done ', '[', '\\\\n', '\\\\n  ', '\\\\n    ', '\\\\n      ', '\\\\n        ', '\\\\n          ', '\\\\n            ', '\\\\n              ', '\\\\n                ', '\\\\n                    ', '\\\\n                      ', '\\\\n\\\\n', '\\\\n\\\\n  ', '\\\\n\\\\n    ', '\\\\n\\\\n          ', '\\\\n\\\\n\\\\n', '\\\\n\\\\n\\\\n    ', ']', 'a_main2_text', 'a_main_button', 'a_main_container', 'a_main_text', 'a_transaction_list_container', 'a_transaction_list_recycler', 'abstract', 'activity_main', 'activity_main2', 'activity_transaction_list', 'adapt', 'adapter', 'addCallAdapterFactory', 'addConverterFactory', 'addition_isCorrect', 'also', 'amount', 'amount_cents', 'amount_currency', 'android', 'annotation', 'annotations', 'app', 'appContext', 'application/json', 'apply', 'arch', 'asString', 'assert', 'assertEquals', 'atomic', 'baseUrl', 'bind', 'body', 'bp', 'build', 'butterknife', 'by', 'call', 'canonicalName', 'class', 'clazz', 'com', 'com.ground0.transaction', 'companion', 'compareAndSet', 'components', 'concurrent', 'const', 'constructor', 'content', 'context', 'converter', 'core', 'create', 'createItemViewModel', 'createdAt', 'created_at', 'currency', 'currentTimeMillis', 'customer', 'customerId', 'customer_id', 'customers', 'd', 'dao', 'databaseBuilder', 'databaseImp', 'databinding', 'db', 'deserialize', 'design', 'disposables', 'e', 'else', 'email', 'entities', 'error', 'errorEvent', 'false', 'findViewById', 'format', 'from', 'fromCallable', 'fun', 'functions', 'get', 'getCustomer', 'getCustomers', 'getItemCount', 'getNon', 'getRetailer', 'getRetailers', 'getTargetContext', 'getTransaction', 'getTransactions', 'google', 'ground0', 'gson', 'hasActiveObservers', 'holder', 'http', 'id', 'if', 'import', 'inflate', 'init', 'initRecyclerView', 'initViewModel', 'inner', 'insert', 'interface', 'internal', 'io', 'isSuccessful', 'it', 'itemView', 'itemViewModel', 'item_transaction', 'jakewharton', 'java', 'javaClass', 'joinToString', 'json', 'junit', 'kotlinx', 'lang', 'lateinit', 'layout', 'layoutManager', 'lazy', 'let', 'lifecycle', 'list', 'listOf', 'livedata', 'loadTransactions', 'mPending', 'main', 'mainThread', 'make', 'makeText', 'map', 'message', 'model', 'name', 'network', 'non_existant', 'not implemented', 'notifyDataSetChanged', 'null', 'object', 'observe', 'observeOn', 'observer', 'of', 'okhttp3', 'onBindViewHolder', 'onButtonClick', 'onChanged', 'onConflict', 'onCreate', 'onCreateViewHolder', 'onError', 'onSubscribe', 'onSuccess', 'open', 'org', 'os', 'override', 'owner', 'package', 'packageName', 'parent', 'parse', 'persistence', 'phone', 'position', 'postCustomers', 'postRetailer', 'postRetailers', 'postTransaction', 'postTransactions', 'println', 'private', 'protected', 'reactivestreams', 'reactivex', 'recyclerView', 'reflect', 'registerTypeAdapter', 'repository', 'response', 'restImp', 'retailTransaction', 'retailTransactions', 'retail_transactions', 'retailer', 'retailerId', 'retailer_id', 'retailers', 'retrofit', 'retrofit2', 'return', 'room', 'runner', 'rxjava2', 'savedInstanceState', 'schedulers', 'serialize', 'set', 'setContentView', 'setSupportActionBar', 'setValue', 'shouldCallOnErrorFor404', 'shouldCallOnSuccessFor200', 'show', 'showTransactions', 'size', 'src', 'startActivity', 'statusOperator', 'subscribe', 'subscribeOn', 'subscribeToError', 'subscribeToMessages', 'subscribeToTransactions', 'success', 'super', 'support', 'switchMapSingle', 'synthetic', 't', 'tableName', 'test', 'text', 'this', 'threeten', 'threetenabp', 'toDate', 'toObservable', 'toString', 'toolbar', 'transaction', 'transaction/{transactionId}', 'transactionDao', 'transactionId', 'transactionListAdapter', 'transactionListItemViewModelFactory', 'transaction_db', 'transactions', 'true', 'typeOfSrc', 'typeOfT', 'updatedAt', 'updated_at', 'useAppContext', 'util', 'v4', 'v7', 'val', 'value', 'var', 'version', 'view', 'viewModel', 'viewType', 'w', 'widget', '{', '}']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizerValue.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "featuresFileName = \"features_token.tsv\"\n",
    "\n",
    "token_types = vectorizer.get_feature_names()\n",
    "res = vectors.toarray()\n",
    "with open(featuresFileName, 'w') as tsv_file:\n",
    "    tsv_writer = csv.writer(tsv_file, delimiter='\\t', lineterminator='\\n')\n",
    "    tsv_writer.writerow([\"ID\", \"Path\"] + token_types)\n",
    "    i = 1\n",
    "    for line in res:\n",
    "        #print([i] + list(line))\n",
    "        tsv_writer.writerow([i] + [files_list[i - 1]] + list(line))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
